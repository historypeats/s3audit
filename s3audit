#!/usr/bin/env python

#
#	Author: historypeats <iam.historypeats@gmail.com>
#	Description: This tool can be used to audit your S3 Buckets
#	To find out what buckets and files have publicly exposed read permissions
#
#	Requirements: 
#		- boto
#		- blessings
#

from boto.s3.connection import S3Connection, S3ResponseError
from blessings import Terminal
from Queue import Queue
from threading import Thread
from time import gmtime, strftime
from collections import Counter
import sys
import argparse
import os
import urlparse

#
#	DEFAULT VALUES
#
DEFAULT_THREADS = 10
DEFAULT_OUTFILE = '{0}.results'.format(sys.argv[0])


# 
#	Threading Classes
#
class S3Thread(Thread):
	''' This class handles threading for retrieving S3 information '''

	def __init__(self, keyQueue, resultsQueue):
		''' Constructor '''
		Thread.__init__(self)
		self.keys = keyQueue
		self.results = resultsQueue

	def findPerms(self, key):
		''' Finds the permissions of a key and stores the result in a result queue '''
		
		try:
			kname = str(key.name)
			t = Terminal()
			for auth in key.get_acl().acl.grants:
				if auth.permission == 'READ':
					#print 'public: {0}'.format(kname)
					self.results.put(kname)

		except S3ResponseError:
			print t.red +'[!] Key does not exist: {0}'.format(kname) + t.normal

		except:
			print t.red + '[!] Uknown error in find_public() with key: {0}'.format(kname) + t.normal

	def run(self):
		''' Thread Run '''
		while True:
			self.key = self.keys.get()
			self.findPerms(self.key)
			self.keys.task_done()


#
#	Functions
#
def getKeys(bucket):
	''' This returns a list of keys from a bucket '''
	conn = None
	try:
		t = Terminal()
		keys = list()
		
		print '[+] Getting keys for bucket {0}. This may take some time...'.format(bucket)
		
		conn = S3Connection()
		bucket = conn.get_bucket(bucket)
		kObject = bucket.list()

		for key in kObject:
			keys.append(key)

		return keys
	except KeyboardInterrupt:
		sys.exit(t.red + '[!] ^C entered. Exiting.' + t.normal)

	except S3ResponseError:
		sys.exit(t.red + '[!] Bucket {0} either does not exist or you do not have permissions to access it.'.format(bucket) + t.normal)
	
	except:
		sys.exit(t.red + '[!] Unknown error in getKeys()' + t.normal)

	finally:
		if conn:
			conn.close()

def initArgs():
	''' Initialize Argparse '''

	parser = argparse.ArgumentParser(description='S3 Auditing Tool')
	parser.add_argument('bucket', help='The S3 bucket to audit.', type=str)
	parser.add_argument('-o', dest='outfile', help='The output file.', type=str, default=DEFAULT_OUTFILE)
	parser.add_argument('-t', dest='threads', help='How many threads to use.', type=int, default=DEFAULT_THREADS)

	return parser.parse_args()

def stats(totalKeys, results, bucket):
	''' Print stats regarding exposed files '''
	
	fd = None
	try:
		t = Terminal()
		fd = open('{0}.stats'.format(bucket), 'w')
		
		print 'Total Keys in Bucket: {0}'.format(str(totalKeys))
		print 'Keys public to the interwebs: {0}'.format(str(len(results)))

		fd.write('Total Keys in Bucket: {0}\n'.format(str(totalKeys)))
		fd.write('Keys public to the interwebs: {0}\n'.format(str(len(results))))
		
		filetypes = list()

		for result in results:
			path = urlparse.urlparse(result.strip()).path
			ext = os.path.splitext(path)[1]

			if ext == '':
				filetypes.append('other')
			else:
				filetypes.append(ext)

		ct = Counter(filetypes).most_common()

		print 'File types found: '
		fd.write('File types found: \n')

		for i in ct:
			print '\t{0} - {1}'.format(i[0], i[1])
			fd.write('\t{0} - {1}\n'.format(i[0], i[1]))
	except:
		print t.red + '[!] Error saving stats to file.' + t.normal
	finally:
		if fd:
			fd.close()
#
#	Main
#
def main():
	''' Main '''

	print '[+] Starting task on {0}'.format(strftime("%m-%d-%Y %I:%M%p", gmtime()))
	# Parse args
	args = initArgs()	

	num_threads = args.threads
	
	# For storing S3 Keys
	keyQueue = Queue(maxsize=0)

	# For storing results and printing
	resultsQueue = Queue(maxsize=0)

	# Get list of keys from bucket
	keys = getKeys(args.bucket)

	print '[+] Retrieved keys. Starting permission enumeration...'
	
	# Put keys into Queue 
	for key in keys:
		keyQueue.put(key)
	
	# Remove this... for DEBUG 30 keys
	'''
	for i in xrange(200):
		keyQueue.put(keys[i])
	'''

	# Start S3 threads
	for t in xrange(num_threads):
		worker = S3Thread(keyQueue, resultsQueue)
		worker.setDaemon(True)
		worker.start()

	# Wait for threads to finish
	keyQueue.join()

	print '[+] Enumeration complete.\n'

	results = list()

	# Store results into a list
	while not resultsQueue.empty():
		results.append(resultsQueue.get())

	# Write results to file	
	with open(args.outfile, 'a') as fd:
		for result in results:
			fd.write('{0}\n'.format(result))

	# Get stats
	print '### Statistics ###'
	stats(len(keys), results, args.bucket)


if __name__ == '__main__':
	main()
